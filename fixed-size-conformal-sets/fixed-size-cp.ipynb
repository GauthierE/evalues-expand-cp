{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib.patches import Patch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file=None, transform=None):\n",
    "        if csv_file:\n",
    "            self.data_frame = pd.read_csv(csv_file, delimiter=',')  # Read CSV file\n",
    "        else:\n",
    "            self.data_frame = pd.DataFrame()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the total number of samples\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # get the binary image data and label\n",
    "        image_bytes = self.data_frame.iloc[idx, 3]  # the image data is in the fourth column\n",
    "        label = int(self.data_frame.iloc[idx, 2])  # the label is in the second column\n",
    "        user_id = self.data_frame.iloc[idx, 0]\n",
    "\n",
    "        # convert the binary data to an image\n",
    "        png_binary = eval(image_bytes)  \n",
    "        image = Image.open(io.BytesIO(png_binary)) \n",
    "\n",
    "        # apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, user_id\n",
    "    \n",
    "    def filter_indices_by_user(self, user_id):\n",
    "        return self.data_frame[self.data_frame.iloc[:, 0] == user_id].index.tolist()\n",
    "\n",
    "# define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor() \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(\n",
    "    csv_file='test.csv',\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet62()\n",
    "\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "checkpoint_path = \"weights/LeNet_0.1_100_512_SGD\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# load the weights into the model\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1) # used for the computation of the loss\n",
    "\n",
    "# for iteration\n",
    "proba = 0\n",
    "alphas_mins = []\n",
    "Niter = 100\n",
    "ratios = []\n",
    "\n",
    "C = 3 # max target size of the conformal set\n",
    "alphas = np.arange(0.01,0.31,0.01)\n",
    "\n",
    "for iter in range(Niter):\n",
    "    print(iter)\n",
    "\n",
    "    # randomize calibration/final test sets\n",
    "    indices = np.random.permutation(len(test_dataset.data_frame))\n",
    "    calibration_indices = indices[:2000]\n",
    "    final_test_indices = indices[2000:4000]\n",
    "    final_test_size = len(final_test_indices)\n",
    "    calibration_df = test_dataset.data_frame.iloc[calibration_indices]\n",
    "    final_test_df = test_dataset.data_frame.iloc[final_test_indices]\n",
    "    calibration_set = CustomImageDataset(csv_file=None, transform=transform)\n",
    "    calibration_set.data_frame = calibration_df.reset_index(drop=True)\n",
    "    final_test_set = CustomImageDataset(csv_file=None, transform=transform)\n",
    "    final_test_set.data_frame = final_test_df.reset_index(drop=True)\n",
    "\n",
    "    n_label = len(calibration_set)\n",
    "    conformal_sets = []\n",
    "\n",
    "    # compute scores for calibration samples\n",
    "    scores_calibration = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(calibration_set)):\n",
    "            x_sample, y_true, _ = calibration_set[idx]\n",
    "            x_sample = x_sample.unsqueeze(0).to(device)\n",
    "            y_true = torch.tensor([y_true], dtype=torch.long).to(device)\n",
    "            logits = net(x_sample)\n",
    "            score = criterion(logits, y_true).item()\n",
    "\n",
    "            scores_calibration.append(score)\n",
    "\n",
    "        sum_label = sum(scores_calibration)\n",
    "\n",
    "        # sample one random element from the final test set\n",
    "        random_idx = np.random.choice(final_test_size) \n",
    "        x_random, y_random, _ = final_test_set[random_idx]\n",
    "        y_random = int(y_random) \n",
    "        true_label = y_random\n",
    "\n",
    "        # convert the random test sample to a tensor\n",
    "        x_random_tensor = x_random.unsqueeze(0).to(device)\n",
    "        logits_random = net(x_random_tensor)\n",
    "\n",
    "        model_prediction = torch.argmax(logits_random).item()\n",
    "\n",
    "        for alpha in alphas:\n",
    "\n",
    "            conformal_set = []\n",
    "\n",
    "            for k in range(62): \n",
    "                with torch.no_grad():\n",
    "                    true_label_tensor_random = torch.tensor([k], dtype=torch.long).to(device)\n",
    "                    S = criterion(logits_random, true_label_tensor_random).item()\n",
    "\n",
    "                ratio = (n_label + 1) * S / (sum_label + S)\n",
    "\n",
    "                if ratio < 1 / alpha:\n",
    "                    conformal_set.append(k)\n",
    "            \n",
    "            conformal_sets.append(conformal_set)\n",
    "\n",
    "        # find minimal alpha such that Card(conformal set) <= C\n",
    "        min_index = next((i for i, x in enumerate(conformal_sets) if len(x) <= C), -1)\n",
    "        alpha_min = alphas[min_index]\n",
    "        alphas_mins.append(alpha_min)\n",
    "        \n",
    "        if true_label in conformal_sets[min_index]:\n",
    "            proba += 1\n",
    "            ratios.append(0)\n",
    "        else:\n",
    "            ratios.append(1/alpha_min)\n",
    "\n",
    "        ###########################################################\n",
    "        # PLOT CONFORMAL SETS (binary matrix)\n",
    "        ###########################################################\n",
    "\n",
    "        # characters = [\n",
    "        #     '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "        #     'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',\n",
    "        #     'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "        #     'U', 'V', 'W', 'X', 'Y', 'Z', \n",
    "        #     'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n",
    "        #     'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n",
    "        #     'u', 'v', 'w', 'x', 'y', 'z'\n",
    "        # ]\n",
    "\n",
    "        # fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "        # binary_matrix = np.zeros((len(characters), len(alphas))) \n",
    "        # for col_idx, conformal_set in enumerate(conformal_sets):\n",
    "        #     for label in conformal_set:\n",
    "        #         binary_matrix[label, col_idx] = 1\n",
    "\n",
    "        # im = ax1.imshow(binary_matrix, cmap=\"Blues\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "\n",
    "        # for col_idx in range(len(alphas)):\n",
    "        #     ax1.axvline(col_idx - 0.5, color=\"gray\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # ax1.set_xticks(range(len(alphas)))\n",
    "        # ax1.set_xticklabels([f\"{alpha:.2f}\" for alpha in alphas], fontsize=10)\n",
    "        # ax1.set_xlabel(r\"$\\alpha$\", fontsize=20)\n",
    "        # ax1.set_yticks(range(len(characters)))\n",
    "        # ax1.set_yticklabels(characters, fontsize=14)\n",
    "        # ax1.set_ylabel(\"Labels\", fontsize=20)\n",
    "\n",
    "        # ax2 = ax1.twinx()\n",
    "        # conformal_set_sizes = [len(conformal_set) for conformal_set in conformal_sets]\n",
    "        # ax2.plot(range(len(alphas)), conformal_set_sizes, color=\"#E41A1C\", label=\"Conformal Set Size\", linewidth=3)\n",
    "        # ax2.set_ylabel(\"Conformal Set Size\", fontsize=14, color=\"#E41A1C\")\n",
    "        # ax2.tick_params(axis=\"y\", labelcolor=\"#E41A1C\", labelsize=12)\n",
    "\n",
    "        # dark_blue = plt.cm.Blues(1.0)\n",
    "\n",
    "        # merged_handles = [\n",
    "        #     Patch(color=dark_blue, label=\"Conformal Set\"),\n",
    "        #     plt.Line2D([0], [0], color=\"#E41A1C\", linestyle=\"-\", linewidth=2, markersize=6, label=\"Conformal Set Size\")\n",
    "        # ]\n",
    "        # ax1.legend(handles=merged_handles, loc=\"upper right\", fontsize=16)\n",
    "\n",
    "        # ax2.yaxis.set_major_locator(MultipleLocator(5)) \n",
    "        # ax2.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "        # ax2.set_ylim(0, 62)\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        \n",
    "proba = proba/Niter\n",
    "alpha_mean = sum(alphas_mins)/Niter \n",
    "print(proba)\n",
    "print(1-alpha_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of 1-alpha\n",
    "fig_alpha, ax_alpha = plt.subplots(figsize=(7, 4)) \n",
    "ax_alpha.hist(1-np.array(alphas_mins), color='green',edgecolor='black',alpha=0.6,bins=1-np.array(alphas[::-1]),align='left')\n",
    "ax_alpha.axvline(x=proba, color='red', linestyle='--', linewidth=3)\n",
    "ax_alpha.axvline(x=np.mean(1-np.array(alphas_mins)), color='black', linestyle='--', linewidth=3)\n",
    "ax_alpha.set_xlabel(r\"$1-\\tilde{\\alpha}$\",fontsize=16)\n",
    "ax_alpha.set_ylabel(\"Frequency\",fontsize=16)\n",
    "\n",
    "ax_alpha.set_xlim(0.8,1)\n",
    "ax_alpha.set_ylim(0,45)\n",
    "\n",
    "ax_alpha.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "ax_alpha.set_xticks(np.linspace(0.8, 1.0, 11))\n",
    "ax_alpha.set_xticks(np.linspace(0.8, 1.0, 21),minor=True)\n",
    "\n",
    "ax_alpha.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
